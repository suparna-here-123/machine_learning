{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a33ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cf52fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath) :\n",
    "    # Loading the dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Dropping the column GarbageValues\n",
    "    df.drop([\"GarbageValues\"], axis = 'columns', inplace = True)\n",
    "    \n",
    "    # Dropping rows where 'Outcome' label has null value\n",
    "    df.dropna(subset = [\"Outcome\"], inplace = True)\n",
    "    \n",
    "    # Filling null values in 'Pregnancies' column with 0.0\n",
    "    df[\"Pregnancies\"].fillna(0.0, inplace = True)\n",
    "    \n",
    "    # Filling null values in all other columns to the mean of the column\n",
    "    df.fillna(df.mean(), inplace = True)\n",
    "    \n",
    "    # Splitting data into feature set and label set\n",
    "    features = df.loc[:, df.columns != \"Outcome\"]\n",
    "    outcome = df.loc[:, df.columns == \"Outcome\"]\n",
    "    \n",
    "    return (features, outcome)\n",
    "#load_and_preprocess_data(\"modified_diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84ef0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "def split_and_standardize(X, y) :\n",
    "    # First splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 5)\n",
    "    \n",
    "    # Now normalising the FEATURES of train and test set\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_features = scaler.fit_transform(X_train)\n",
    "    scaled_test_features = scaler.fit_transform(X_test)\n",
    "    \n",
    "    return (scaled_train_features, scaled_test_features, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55100f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train) :\n",
    "    model_1 = MLPClassifier(hidden_layer_sizes = (58, 68, 67), \n",
    "                          activation = 'logistic', \n",
    "                          solver = 'adam', \n",
    "                          learning_rate = 'adaptive',\n",
    "                          learning_rate_init = 0.001,\n",
    "                          random_state = 42)\n",
    "    \n",
    "    model_2 = MLPClassifier(hidden_layer_sizes = (60, 60, 60), \n",
    "                          activation = 'relu', \n",
    "                          solver = 'sgd',\n",
    "                          learning_rate = 'constant', \n",
    "                          learning_rate_init = 0.002,\n",
    "                          random_state = 12)\n",
    "    \n",
    "    model_1.fit(X_train, y_train)\n",
    "    model_2.fit(X_train, y_train)\n",
    "    \n",
    "    return (model_1, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb1ad801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, X_test, y_test) :\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return (accuracy, precision, recall, f1, conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dda71c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7034/1898704873.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Pregnancies\"].fillna(0.0, inplace = True)\n",
      "/home/suppra/pytorch_env/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1105: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/suppra/pytorch_env/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/suppra/pytorch_env/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1105: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1\n",
      "accuracy  0.7587719298245614\n",
      "precision  0.75\n",
      "recall 0.5730337078651685\n",
      "f1 score  0.6496815286624203\n",
      "conf  [[122  17]\n",
      " [ 38  51]]\n",
      "\n",
      "MODEL 2\n",
      "accuracy  0.7543859649122807\n",
      "precision  0.7538461538461538\n",
      "recall 0.550561797752809\n",
      "f1 score  0.6363636363636364\n",
      "conf  [[123  16]\n",
      " [ 40  49]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suppra/pytorch_env/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features, outcome = load_and_preprocess_data(\"./modified_diabetes.csv\")\n",
    "X_train, X_test, y_train, y_test = split_and_standardize(features, outcome)\n",
    "model_1, model_2 = create_model(X_train, y_train)\n",
    "\n",
    "a1, p1, r1, f1_1, c1 = predict_and_evaluate(model_1, X_test, y_test)\n",
    "print(\"MODEL 1\")\n",
    "print(\"accuracy \", a1)\n",
    "print(\"precision \", p1)\n",
    "print(\"recall\", r1)\n",
    "print(\"f1 score \", f1_1)\n",
    "print(\"conf \", c1)\n",
    "\n",
    "print()\n",
    "\n",
    "a2, p2, r2, f1_2, c2 = predict_and_evaluate(model_2, X_test, y_test)\n",
    "print(\"MODEL 2\")\n",
    "print(\"accuracy \", a2)\n",
    "print(\"precision \", p2)\n",
    "print(\"recall\", r2)\n",
    "print(\"f1 score \", f1_2)\n",
    "print(\"conf \", c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a8589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d85d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_kernel",
   "language": "python",
   "name": "pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
